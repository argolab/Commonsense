{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import mrf\n",
    "import AgentS1\n",
    "import AgentS2\n",
    "import utils\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "class RunAgents():\n",
    "    def __init__(self, question_schema, prompts, log_dir, city, model_dial, model_trans, chat_temp):\n",
    "        # check if log_dir exists, if not add\n",
    "\n",
    "        self.question_schema = question_schema\n",
    "        self.prompts = prompts\n",
    "        path = Path(log_dir)\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self.log_dir = log_dir\n",
    "        self.city = city\n",
    "        self.model_dial = model_dial\n",
    "        self.model_trans = model_trans\n",
    "        self.chat_temp = chat_temp\n",
    "\n",
    "    \n",
    "    def run_agents(self):\n",
    "        self.agents1 = AgentS1.AgentS1(self.prompts, self.question_schema, city=self.city, log_dir=self.log_dir, log_name='agents1.json', model_dial=self.model_dial, model_trans=self.model_trans, chat_temp=self.chat_temp)\n",
    "        \n",
    "        s1_schema = self.agents1.compile()\n",
    "\n",
    "        self.agents2 = AgentS2.AgentS2(self.prompts, s1_schema, city=self.city, log_dir=self.log_dir, log_name='agents2.json', model_dial=self.model_dial, model_trans=self.model_trans, chat_temp=self.chat_temp)\n",
    "\n",
    "        s2_schema = self.agents2.compile()\n",
    "\n",
    "        # save s2_schema\n",
    "        json.dump(s2_schema, open(f'{self.log_dir}/agents.json', 'w'), indent=4)\n",
    "\n",
    "        return s2_schema\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using schema:  {\"Variables\": [{\"Name\": \"Host Experience Level\", \"Value\": [\"Less than 1 year\", \"1-3 years\", \"4-6 years\", \"7 years and above\"]}, {\"Name\": \"Property Type\", \"Value\": [\"Apartment\", \"House\", \"Condo\", \"Villa\"]}, {\"Name\": \"Location\", \"Value\": [\"Beachfront\", \"Downtown\", \"Suburban\", \"Rural\"]}, {\"Name\": \"Amenities\", \"Value\": [\"Basic (e.g., Wi-Fi, TV)\", \"Standard (e.g., kitchen, air conditioning)\", \"Premium (e.g., pool, hot tub)\", \"Luxury (e.g., private chef, gym)\"]}, {\"Name\": \"Seasonality\", \"Value\": [\"Peak Season (e.g., summer, holidays)\", \"Off-Peak Season (e.g., winter, weekdays)\", \"Special Events (e.g., concerts, festivals)\"]}, {\"Name\": \"Property Size\", \"Value\": [\"Studio/1 bedroom\", \"2 bedrooms\", \"3 bedrooms\", \"4 bedrooms and above\"]}, {\"Name\": \"Price\", \"Value\": [\"$0-$50\", \"$51-$100\", \"$101-$200\", \"$201-$500\", \"$501 and above\"]}]}\n",
      "Evaluating BrowardCounty\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Experiments/tt/BrowardCounty/ent1.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 129\u001b[0m\n\u001b[1;32m    126\u001b[0m test\u001b[38;5;241m.\u001b[39mrun_agent()\n\u001b[1;32m    127\u001b[0m test\u001b[38;5;241m.\u001b[39mload_experiments()\n\u001b[0;32m--> 129\u001b[0m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m ret \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "Cell \u001b[0;32mIn[104], line 87\u001b[0m, in \u001b[0;36mevaluation_suite.get_results\u001b[0;34m(self, w0, update_iter)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m question, schema \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_records\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvaluating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 87\u001b[0m     mrf_obj \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mquestion\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/ent\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mw0\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     mrf_result \u001b[38;5;241m=\u001b[39m mrf_obj\u001b[38;5;241m.\u001b[39mquery(schema[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mschema\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     91\u001b[0m     zero_result \u001b[38;5;241m=\u001b[39m schema[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzero shot\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProbability\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dl/lib/python3.8/site-packages/torch/serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    996\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dl/lib/python3.8/site-packages/torch/serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dl/lib/python3.8/site-packages/torch/serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 426\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Experiments/tt/BrowardCounty/ent1.pt'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "import torch\n",
    "reload(mrf)\n",
    "reload(AgentS1)\n",
    "reload(AgentS2)\n",
    "reload(utils)\n",
    "reload(evaluate)\n",
    "\n",
    "class evaluation_suite():\n",
    "    def __init__(self, question_folder, identifier='', log_dir='./Experiments', prompts='./data/prompts_13.json', model_dial='gpt-4o', model_trans='gpt-3.5', chat_temp=0.3, data_folder='./data/'):\n",
    "\n",
    "        self.question_folder = question_folder\n",
    "        if identifier == '':\n",
    "            self.identifier = str(datetime.datetime.now().strftime('%m%d_%H%M'))\n",
    "        else:\n",
    "            self.identifier = identifier\n",
    "\n",
    "        self.prompts = prompts\n",
    "\n",
    "        self.log_dir = log_dir\n",
    "\n",
    "        self.model_dial = model_dial\n",
    "        self.model_trans = model_trans\n",
    "        self.chat_temp = chat_temp\n",
    "        self.data_folder = data_folder\n",
    "\n",
    "        self.agent_records = {}\n",
    "        self.exp_records = {}\n",
    "\n",
    "\n",
    "\n",
    "    def run_agent(self, ):\n",
    "\n",
    "        # load questions from folder\n",
    "        question_folder = Path(self.question_folder)\n",
    "        question_files = list(question_folder.glob('*.json'))\n",
    "        for question in question_files:\n",
    "            question_schema = json.load(open(question))\n",
    "\n",
    "\n",
    "            city = question_schema['City']\n",
    "            question_schema.pop('City')\n",
    "            # remove state after \", \"\n",
    "            question_name = city.split(',')[0].replace(' ', '')\n",
    "\n",
    "            run_agents = RunAgents(question_schema=question_schema, prompts=self.prompts, log_dir=self.log_dir+f'/{question_name}', city=city, model_dial=self.model_dial, model_trans=self.model_trans, chat_temp=self.chat_temp)\n",
    "\n",
    "            s2_schema_records = run_agents.run_agents()\n",
    "\n",
    "            self.agent_records[question_name] = s2_schema_records\n",
    "            \n",
    "\n",
    "    def load_experiments(self, ):\n",
    "        # load experiments *_schema.json\n",
    "        question_folder = Path(self.log_dir)\n",
    "        # get all folders under question folder, not files\n",
    "        question_folders = [x for x in question_folder.iterdir() if x.is_dir() and '.' not in x.stem]\n",
    "        for question in question_folders:\n",
    "            question_name = question.stem\n",
    "            schema = json.load(open(f'{question}/agents2.json'))\n",
    "            self.agent_records[question_name] = schema\n",
    "\n",
    "\n",
    "    def optimize_mrf(self, w0=0, update_iter=10000):\n",
    "\n",
    "        for question, schema in self.agent_records.items():\n",
    "            print(f'Evaluating {question}')\n",
    "            mrf_obj = mrf.Brute(verbose=False)\n",
    "            mrf_obj.from_json(schema['schema'])\n",
    "            if w0 != 0:\n",
    "                mrf_obj.set_w0(w0)\n",
    "            mrf_obj.update(update_iter)\n",
    "\n",
    "            # save model to same directory\n",
    "            torch.save(mrf_obj, f'{self.log_dir}/{question}/ent{str(w0)}.pt')\n",
    "        \n",
    "\n",
    "    def get_results(self, w0=0, ):\n",
    "        \n",
    "        for question, schema in self.agent_records.items():\n",
    "\n",
    "            print(f'Evaluating {question}')\n",
    "            try:\n",
    "                mrf_obj = torch.load(f'{self.log_dir}/{question}/ent{str(w0)}.pt')\n",
    "                mrf_result = mrf_obj.query(schema['schema'])\n",
    "            except:\n",
    "                mrf_result = 0\n",
    "            zero_result = schema['zero shot']['result']['Probability']\n",
    "            cot_result = schema['cot']['result']['Probability']\n",
    "            # data folder\n",
    "            dat_path = Path(self.data_folder + '/' + question + '.csv')\n",
    "            data = utils.DatasetQ(dat_path)\n",
    "            ground_truth = data.marg(schema['schema']['Question'])\n",
    "            self.exp_records[question] = {'mrf': mrf_result, 'zero_shot': zero_result, 'cot': cot_result, 'ground_truth': ground_truth}\n",
    "            \n",
    "            json.dump(self.exp_records[question], open(f'{self.log_dir}/{question}/run_results{str(w0)}.json', 'w'), indent=4)\n",
    "\n",
    "\n",
    "\n",
    "    def evaluate(self,):\n",
    "\n",
    "        table = [[\"City\", \"Zero Shot\", \"Ground\", \"MRF\", \"Change\", \"Zero TVD\", \"MRF TVD\"]]\n",
    "\n",
    "        for city, results in self.exp_records.items():\n",
    "            tmp = []\n",
    "            mrf_ground = evaluate.total_variation_distance(results['ground_truth'], results['mrf'])\n",
    "            zero_shot_ground = evaluate.total_variation_distance(results['ground_truth'], results['zero_shot'])\n",
    "            tmp.append(city)\n",
    "            tmp.append(np.array(results['zero_shot']).round(3))\n",
    "            tmp.append(np.array(results['ground_truth']).round(3))\n",
    "            tmp.append(np.array(results['mrf']).round(3))\n",
    "            tmp.append((mrf_ground - zero_shot_ground).round(3))\n",
    "            tmp.append(zero_shot_ground.round(3))\n",
    "            tmp.append(mrf_ground.round(3))\n",
    "            table.append(tmp)\n",
    "\n",
    "        print(tabulate(table))\n",
    "        return table\n",
    "\n",
    "\n",
    "test = evaluation_suite(question_folder='./Testing', identifier='test', log_dir='./Experiments/', prompts='./prompts_13.json', model_dial='gpt-3.5-turbo', model_trans='gpt-3.5-turbo', chat_temp=0.1)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# How to use\n",
    "question_folder: folder with json question files. If you run this script only to get one run on one city, separate the questions so question_folder is './Questions/BrowardCounty' and your question file like './Questions/BrowardCounty/question.json', no restriction on the file name\n",
    "\n",
    "\n",
    "identifier: ignore this\n",
    "\n",
    "\n",
    "log_dir: directory to save results. Similarly if one run one city, set log_dir to './Experiments/run_1'. Script will create and populate folder './Experiments/run_1/BrowardCounty'\n",
    "\n",
    "\n",
    "prompts: fixed path to the prompts file, it contains all prompts needed\n",
    "\n",
    "\n",
    "\n",
    "data_folder: fixed path to the data folder. if set to './data/', will look for csv './data/BrowardCounty.csv'\n",
    "\n",
    "\n",
    "the rest are intuitive\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# This will iterate over all questions, one in this case, including cot and zero shot, and save the results in the log_dir/cityname/ folder\n",
    "test.run_agent()\n",
    "\n",
    "\n",
    "# load the saved experiment files that resulted from the previous step\n",
    "test.load_experiments()\n",
    "\n",
    "\n",
    "# this will optimize the MRF model, w0=0 will be faster, automatically save the model to the same folder log_dir/cityname/\n",
    "test.optimize_mrf(w0=0)\n",
    "\n",
    "\n",
    "\n",
    "# get results, this only attempts to load mrf from local. If it doesn't exist, it will record other results and dump in log_dir/cityname/\n",
    "test.get_results(w0=0)\n",
    "\n",
    "\n",
    "\n",
    "# this will print the tabulate\n",
    "ret = test.evaluate()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
