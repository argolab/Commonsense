{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import mrf\n",
    "import AgentS1\n",
    "import AgentS2\n",
    "import utils\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "class RunAgents():\n",
    "    def __init__(self, question_schema, prompts, log_dir, city, model_dial, model_trans, chat_temp):\n",
    "        # check if log_dir exists, if not add\n",
    "\n",
    "        self.question_schema = question_schema\n",
    "        self.prompts = prompts\n",
    "        path = Path(log_dir)\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self.log_dir = log_dir\n",
    "        self.city = city\n",
    "        self.model_dial = model_dial\n",
    "        self.model_trans = model_trans\n",
    "        self.chat_temp = chat_temp\n",
    "\n",
    "    \n",
    "    def run_agents(self):\n",
    "        self.agents1 = AgentS1.AgentS1(self.prompts, self.question_schema, city=self.city, log_dir=self.log_dir, log_name='agents1.json', model_dial=self.model_dial, model_trans=self.model_trans, chat_temp=self.chat_temp)\n",
    "        \n",
    "        s1_schema = self.agents1.compile()\n",
    "\n",
    "        self.agents2 = AgentS2.AgentS2(self.prompts, s1_schema, city=self.city, log_dir=self.log_dir, log_name='agents2.json', model_dial=self.model_dial, model_trans=self.model_trans, chat_temp=self.chat_temp)\n",
    "\n",
    "        s2_schema = self.agents2.compile()\n",
    "\n",
    "        # save s2_schema\n",
    "        json.dump(s2_schema, open(f'{self.log_dir}/agents.json', 'w'), indent=4)\n",
    "\n",
    "        return s2_schema\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "import torch\n",
    "reload(mrf)\n",
    "reload(AgentS1)\n",
    "reload(AgentS2)\n",
    "reload(utils)\n",
    "reload(evaluate)\n",
    "\n",
    "class evaluation_suite():\n",
    "    def __init__(self, question_folder, identifier='', log_dir='./Experiments', prompts='./data/prompts_13.json', model_dial='gpt-4o', model_trans='gpt-3.5', chat_temp=0.3, data_folder='./data/'):\n",
    "\n",
    "        self.question_folder = question_folder\n",
    "        if identifier == '':\n",
    "            self.identifier = str(datetime.datetime.now().strftime('%m%d_%H%M'))\n",
    "        else:\n",
    "            self.identifier = identifier\n",
    "\n",
    "        self.prompts = prompts\n",
    "\n",
    "        self.log_dir = log_dir\n",
    "\n",
    "        self.model_dial = model_dial\n",
    "        self.model_trans = model_trans\n",
    "        self.chat_temp = chat_temp\n",
    "        self.data_folder = data_folder\n",
    "\n",
    "        self.agent_records = {}\n",
    "        self.exp_records = {}\n",
    "\n",
    "\n",
    "\n",
    "    def run_agent(self, ):\n",
    "\n",
    "        # load questions from folder\n",
    "        question_folder = Path(self.question_folder)\n",
    "        question_files = list(question_folder.glob('*.json'))\n",
    "        for question in question_files:\n",
    "            question_schema = json.load(open(question))\n",
    "\n",
    "\n",
    "            city = question_schema['City']\n",
    "            question_schema.pop('City')\n",
    "            # remove state after \", \"\n",
    "            question_name = city.split(',')[0].replace(' ', '')\n",
    "\n",
    "            run_agents = RunAgents(question_schema=question_schema, prompts=self.prompts, log_dir=self.log_dir+f'/{question_name}', city=city, model_dial=self.model_dial, model_trans=self.model_trans, chat_temp=self.chat_temp)\n",
    "\n",
    "            s2_schema_records = run_agents.run_agents()\n",
    "\n",
    "            self.agent_records[question_name] = s2_schema_records\n",
    "            \n",
    "\n",
    "    def load_experiments(self, ):\n",
    "        # load experiments *_schema.json\n",
    "        question_folder = Path(self.log_dir)\n",
    "        # get all folders under question folder, not files\n",
    "        question_folders = [x for x in question_folder.iterdir() if x.is_dir() and '.' not in x.stem]\n",
    "        for question in question_folders:\n",
    "            question_name = question.stem\n",
    "            schema = json.load(open(f'{question}/agents2.json'))\n",
    "            self.agent_records[question_name] = schema\n",
    "            print(schema['schema']['Variables'])\n",
    "\n",
    "\n",
    "    def optimize_mrf(self, w0=0, update_iter=50000):\n",
    "\n",
    "        for question, schema in self.agent_records.items():\n",
    "            print(f'Evaluating {question}')\n",
    "            print(schema['schema'])\n",
    "            mrf_obj = mrf.Brute(verbose=True)\n",
    "            #tmp = schema['schema'].copy()\n",
    "            #tmp = remove_vars(tmp, [], one='Price')\n",
    "            mrf_obj.from_json(schema['schema'])\n",
    "            #print(schema['schema']['Constraints'])\n",
    "            #mrf_obj.from_json(tmp)\n",
    "            if w0 != 0:\n",
    "                mrf_obj.set_w0(w0)\n",
    "            mrf_obj.update(update_iter, slack=False)\n",
    "\n",
    "            # save model to same directory\n",
    "            torch.save(mrf_obj, f'{self.log_dir}/{question}/ent{str(w0)}.pt')\n",
    "        \n",
    "\n",
    "    def get_results(self, w0=0, ):\n",
    "        \n",
    "        for question, schema in self.agent_records.items():\n",
    "\n",
    "            print(f'Evaluating {question}')\n",
    "            try:\n",
    "                mrf_obj = torch.load(f'{self.log_dir}/{question}/ent{str(w0)}.pt')\n",
    "                mrf_result = mrf_obj.query(schema['schema'])\n",
    "            except:\n",
    "                mrf_result = 0\n",
    "            zero_result = schema['zero shot']['result']['Probability']\n",
    "            cot_result = schema['cot']['result']['Probability']\n",
    "            # data folder\n",
    "            dat_path = Path(self.data_folder + '/' + question + '.csv')\n",
    "            data = utils.DatasetQ(dat_path)\n",
    "            ground_truth = data.marg(schema['schema']['Question'])\n",
    "            self.exp_records[question] = {'mrf': mrf_result, 'zero_shot': zero_result, 'cot': cot_result, 'ground_truth': ground_truth}\n",
    "            \n",
    "            json.dump(self.exp_records[question], open(f'{self.log_dir}/{question}/run_results{str(w0)}.json', 'w'), indent=4)\n",
    "\n",
    "\n",
    "\n",
    "    def evaluate(self,):\n",
    "\n",
    "        table = [[\"City\", \"Zero Shot\", \"Ground\", \"MRF\", \"CoT\", \"Zero TVD\", \"MRF TVD\", \"CoT TVD\"]]\n",
    "\n",
    "        for city, results in self.exp_records.items():\n",
    "            tmp = []\n",
    "            #print(results)\n",
    "            mrf_ground = evaluate.total_variation_distance(results['ground_truth'], results['mrf'])\n",
    "            zero_shot_ground = evaluate.total_variation_distance(results['ground_truth'], results['zero_shot'])\n",
    "            cot_ground = evaluate.total_variation_distance(results['ground_truth'], results['cot'])\n",
    "            tmp.append(city)\n",
    "            tmp.append(np.array(results['zero_shot']).round(3))\n",
    "            tmp.append(np.array(results['ground_truth']).round(3))\n",
    "            tmp.append(np.array(results['mrf']).round(3))\n",
    "            tmp.append(np.array(results['cot']).round(3))\n",
    "            #tmp.append((mrf_ground - zero_shot_ground).round(3))\n",
    "            tmp.append(zero_shot_ground.round(3))\n",
    "            tmp.append(mrf_ground.round(3))\n",
    "            tmp.append(cot_ground.round(3))\n",
    "            table.append(tmp)\n",
    "\n",
    "        print(tabulate(table))\n",
    "        return table\n",
    "\n",
    "\n",
    "test = evaluation_suite(question_folder='./test_questions2/LosAngeles_0', identifier='test', log_dir='./Experiments2', prompts='./data/prompts_13.json', model_dial='gpt-4o', model_trans='gpt-3.5-turbo', chat_temp=0)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# How to use\n",
    "question_folder: folder with json question files. If you run this script only to get one run on one city, separate the questions so question_folder is './Questions/BrowardCounty' and your question file like './Questions/BrowardCounty/question.json', no restriction on the file name\n",
    "\n",
    "\n",
    "identifier: ignore this\n",
    "\n",
    "\n",
    "log_dir: directory to save results. Similarly if one run one city, set log_dir to './Experiments/run_1'. Script will create and populate folder './Experiments/run_1/BrowardCounty'\n",
    "\n",
    "\n",
    "prompts: fixed path to the prompts file, it contains all prompts needed\n",
    "\n",
    "\n",
    "\n",
    "data_folder: fixed path to the data folder. if set to './data/', will look for csv './data/BrowardCounty.csv'\n",
    "\n",
    "\n",
    "the rest are intuitive\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# This will iterate over all questions, one in this case, including cot and zero shot, and save the results in the log_dir/cityname/ folder\n",
    "test.run_agent()\n",
    "\n",
    "\n",
    "# load the saved experiment files that resulted from the previous step\n",
    "test.load_experiments()\n",
    "\n",
    "\n",
    "# this will optimize the MRF model, w0=0 will be faster, automatically save the model to the same folder log_dir/cityname/\n",
    "test.optimize_mrf(w0=0.4, update_iter=10000)\n",
    "\n",
    "\n",
    "\n",
    "# get results, this only attempts to load mrf from local. If it doesn't exist, it will record other results and dump in log_dir/cityname/\n",
    "test.get_results(w0=0.4)\n",
    "\n",
    "\n",
    "\n",
    "# this will print the tabulate\n",
    "ret = test.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_vars(constraints, vars, one=''):\n",
    "    ret = {}\n",
    "    ret['Variables'] = []\n",
    "    ret['Constraints'] = []\n",
    "    check = set()\n",
    "    for var in constraints['Variables']:\n",
    "        if var['Name'] not in vars:\n",
    "            ret['Variables'].append(var)\n",
    "    for cons in constraints['Constraints']:\n",
    "        if cons is None:\n",
    "            print(\"None\")\n",
    "            continue\n",
    "        if cons['Target'][0]['Name'] not in vars and (len(cons['Condition']) == 0 or (cons['Condition'][0]['Name'] not in vars)):\n",
    "            if len(cons['Condition']) != 0 or cons['Target'][0]['Name'] != one:\n",
    "                print(cons['Target'][0]['Name'], cons['Condition'])\n",
    "                tt = {}\n",
    "                tt['Target'] = cons['Target']\n",
    "                tt['Probability'] = cons['Probability']\n",
    "                #tt['Question'] = cons['Question']\n",
    "                tt['Condition'] = []\n",
    "                for cond in cons['Condition']:\n",
    "                    if cond['Name'] == 'City':\n",
    "                        continue\n",
    "                    tt['Condition'].append(cond)\n",
    "                ret['Constraints'].append(tt)\n",
    "            else:\n",
    "                print(\"here\")\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
